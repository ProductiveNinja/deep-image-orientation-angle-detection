{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff36a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87ebae1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-15 14:37:20.173729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "from layers import mlp, Patches, PatchEncoder\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c95c233a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 100\n",
    "input_shape = (32, 32, 3)\n",
    "\n",
    "learning_rate = 0.001\n",
    "weight_decay = 0.0001\n",
    "batch_size = 256\n",
    "num_epochs = 100\n",
    "image_size = 72  # We'll resize input images to this size\n",
    "patch_size = 6  # Size of the patches to be extract from the input images\n",
    "num_patches = (image_size // patch_size) ** 2\n",
    "projection_dim = 64\n",
    "num_heads = 4\n",
    "transformer_units = [\n",
    "    projection_dim * 2,\n",
    "    projection_dim,\n",
    "]  # Size of the transformer layers\n",
    "transformer_layers = 8\n",
    "mlp_head_units = [2048, 1024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "430b0d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create architecture\n",
    "def tag_cnn_architecture():\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    # Create patches.\n",
    "    patches = Patches(patch_size)(inputs)\n",
    "    # Encode patches.\n",
    "    encoded_patches = PatchEncoder(num_patches, projection_dim)(patches)\n",
    "\n",
    "    # Create multiple layers of the Transformer block.\n",
    "    for _ in range(transformer_layers):\n",
    "        # Layer normalization 1.\n",
    "        x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "        # Create a multi-head attention layer.\n",
    "        attention_output = layers.MultiHeadAttention(\n",
    "            num_heads=num_heads, key_dim=projection_dim, dropout=0.1\n",
    "        )(x1, x1)\n",
    "        # Skip connection 1.\n",
    "        x2 = layers.Add()([attention_output, encoded_patches])\n",
    "        # Layer normalization 2.\n",
    "        x3 = layers.LayerNormalization(epsilon=1e-6)(x2)\n",
    "        # MLP.\n",
    "        x3 = mlp(x3, hidden_units=transformer_units, dropout_rate=0.1)\n",
    "        # Skip connection 2.\n",
    "        encoded_patches = layers.Add()([x3, x2])\n",
    "    \n",
    "    \n",
    "    # get patch attention scores\n",
    "    x1 = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    _, attention_weights = layers.MultiHeadAttention(num_heads=1, key_dim=projection_dim, \n",
    "                                                     dropout=0.1)(x1, x1, return_attention_scores=True)\n",
    "    \n",
    "    print(attention_weights.shape)\n",
    "    \n",
    "    \n",
    "    # Create a [batch_size, projection_dim] tensor.\n",
    "    representation = layers.LayerNormalization(epsilon=1e-6)(encoded_patches)\n",
    "    representation = layers.Flatten()(representation)\n",
    "    representation = layers.Dropout(0.5)(representation)\n",
    "    # Add MLP.\n",
    "    features = mlp(representation, hidden_units=mlp_head_units, dropout_rate=0.5)\n",
    "    # Classify outputs.\n",
    "    logits = layers.Dense(num_classes)(features)\n",
    "    # Create the Keras model.\n",
    "    model = keras.Model(inputs=inputs, outputs=logits)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd175b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 1, 144, 144)\n"
     ]
    }
   ],
   "source": [
    "model = tag_cnn_architecture()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5b5e4a93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "patches_1 (Patches)             (None, None, 108)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "patch_encoder_1 (PatchEncoder)  (None, 144, 64)      16192       patches_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_17 (LayerNo (None, 144, 64)      128         patch_encoder_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_8 (MultiHe (None, 144, 64)      66368       layer_normalization_17[0][0]     \n",
      "                                                                 layer_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 144, 64)      0           multi_head_attention_8[0][0]     \n",
      "                                                                 patch_encoder_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_18 (LayerNo (None, 144, 64)      128         add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_18 (Dense)                (None, 144, 128)     8320        layer_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 144, 128)     0           dense_18[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_19 (Dense)                (None, 144, 64)      8256        dropout_17[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_18 (Dropout)            (None, 144, 64)      0           dense_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_17 (Add)                    (None, 144, 64)      0           dropout_18[0][0]                 \n",
      "                                                                 add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_19 (LayerNo (None, 144, 64)      128         add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_9 (MultiHe (None, 144, 64)      66368       layer_normalization_19[0][0]     \n",
      "                                                                 layer_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_18 (Add)                    (None, 144, 64)      0           multi_head_attention_9[0][0]     \n",
      "                                                                 add_17[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_20 (LayerNo (None, 144, 64)      128         add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_20 (Dense)                (None, 144, 128)     8320        layer_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_19 (Dropout)            (None, 144, 128)     0           dense_20[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_21 (Dense)                (None, 144, 64)      8256        dropout_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_20 (Dropout)            (None, 144, 64)      0           dense_21[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_19 (Add)                    (None, 144, 64)      0           dropout_20[0][0]                 \n",
      "                                                                 add_18[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_21 (LayerNo (None, 144, 64)      128         add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_10 (MultiH (None, 144, 64)      66368       layer_normalization_21[0][0]     \n",
      "                                                                 layer_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_20 (Add)                    (None, 144, 64)      0           multi_head_attention_10[0][0]    \n",
      "                                                                 add_19[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_22 (LayerNo (None, 144, 64)      128         add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_22 (Dense)                (None, 144, 128)     8320        layer_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_21 (Dropout)            (None, 144, 128)     0           dense_22[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 144, 64)      8256        dropout_21[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_22 (Dropout)            (None, 144, 64)      0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_21 (Add)                    (None, 144, 64)      0           dropout_22[0][0]                 \n",
      "                                                                 add_20[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_23 (LayerNo (None, 144, 64)      128         add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_11 (MultiH (None, 144, 64)      66368       layer_normalization_23[0][0]     \n",
      "                                                                 layer_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_22 (Add)                    (None, 144, 64)      0           multi_head_attention_11[0][0]    \n",
      "                                                                 add_21[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_24 (LayerNo (None, 144, 64)      128         add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 144, 128)     8320        layer_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_23 (Dropout)            (None, 144, 128)     0           dense_24[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_25 (Dense)                (None, 144, 64)      8256        dropout_23[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_24 (Dropout)            (None, 144, 64)      0           dense_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_23 (Add)                    (None, 144, 64)      0           dropout_24[0][0]                 \n",
      "                                                                 add_22[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_25 (LayerNo (None, 144, 64)      128         add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_12 (MultiH (None, 144, 64)      66368       layer_normalization_25[0][0]     \n",
      "                                                                 layer_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_24 (Add)                    (None, 144, 64)      0           multi_head_attention_12[0][0]    \n",
      "                                                                 add_23[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_26 (LayerNo (None, 144, 64)      128         add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_26 (Dense)                (None, 144, 128)     8320        layer_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_25 (Dropout)            (None, 144, 128)     0           dense_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 144, 64)      8256        dropout_25[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_26 (Dropout)            (None, 144, 64)      0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_25 (Add)                    (None, 144, 64)      0           dropout_26[0][0]                 \n",
      "                                                                 add_24[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_27 (LayerNo (None, 144, 64)      128         add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_13 (MultiH (None, 144, 64)      66368       layer_normalization_27[0][0]     \n",
      "                                                                 layer_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_26 (Add)                    (None, 144, 64)      0           multi_head_attention_13[0][0]    \n",
      "                                                                 add_25[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_28 (LayerNo (None, 144, 64)      128         add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 144, 128)     8320        layer_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_27 (Dropout)            (None, 144, 128)     0           dense_28[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_29 (Dense)                (None, 144, 64)      8256        dropout_27[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 144, 64)      0           dense_29[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_27 (Add)                    (None, 144, 64)      0           dropout_28[0][0]                 \n",
      "                                                                 add_26[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_29 (LayerNo (None, 144, 64)      128         add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_14 (MultiH (None, 144, 64)      66368       layer_normalization_29[0][0]     \n",
      "                                                                 layer_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_28 (Add)                    (None, 144, 64)      0           multi_head_attention_14[0][0]    \n",
      "                                                                 add_27[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_30 (LayerNo (None, 144, 64)      128         add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_30 (Dense)                (None, 144, 128)     8320        layer_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 144, 128)     0           dense_30[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_31 (Dense)                (None, 144, 64)      8256        dropout_29[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 144, 64)      0           dense_31[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_29 (Add)                    (None, 144, 64)      0           dropout_30[0][0]                 \n",
      "                                                                 add_28[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_31 (LayerNo (None, 144, 64)      128         add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "multi_head_attention_15 (MultiH (None, 144, 64)      66368       layer_normalization_31[0][0]     \n",
      "                                                                 layer_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_30 (Add)                    (None, 144, 64)      0           multi_head_attention_15[0][0]    \n",
      "                                                                 add_29[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_32 (LayerNo (None, 144, 64)      128         add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_32 (Dense)                (None, 144, 128)     8320        layer_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 144, 128)     0           dense_32[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_33 (Dense)                (None, 144, 64)      8256        dropout_31[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 144, 64)      0           dense_33[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_31 (Add)                    (None, 144, 64)      0           dropout_32[0][0]                 \n",
      "                                                                 add_30[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "layer_normalization_33 (LayerNo (None, 144, 64)      128         add_31[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 9216)         0           layer_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 9216)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_34 (Dense)                (None, 2048)         18876416    dropout_33[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_34 (Dropout)            (None, 2048)         0           dense_34[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_35 (Dense)                (None, 1024)         2098176     dropout_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_35 (Dropout)            (None, 1024)         0           dense_35[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_36 (Dense)                (None, 100)          102500      dropout_35[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,759,012\n",
      "Trainable params: 21,759,012\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ac0d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5884c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
